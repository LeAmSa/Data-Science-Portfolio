{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cLlPGkcnRLWK"
   },
   "source": [
    "#  Age range estimation based on CNN DenseNet201\n",
    "- This project represents my undergraduate final work for the Federal Technological University of Parana - Brazil in 2019, whose objective was to realize age range estimation based on a convolutional neural network.\n",
    "\n",
    "- With the technological evolution of social networks and online communities, privacy and security on the Internet have become essential. The high number of information shared by the network supports the spread of illicit content involving child pornography. Computer vision, based on neural networks as a deep learning technique, can recognize characteristics associated with the classification of minors and adults.\n",
    "\n",
    "-  The main focus was to provide subsidies for tools that can use deep learning to identify minors in eventual child pornography content.\n",
    "\n",
    "- For more details about the objectives and technical specifications, read the article in Portuguese by the `ARTIGO.pdf` file. \n",
    "\n",
    "### Dataset\n",
    "![enter image description here](https://susanqq.github.io/UTKFace/icon/logoWall2.jpg)\n",
    "- As data, the recognition process occurred with cropped face images. \n",
    "\n",
    "- The dataset used to train the neural network was __UTKFace Dataset__, made for research based on age, gender, and race.\n",
    "\n",
    "- Files format: ``[age]_[gender]_[race]_[date&time].jpg``\n",
    "\t- `[age]:` integer from 0 to 116, indicating the age;\n",
    "\t- `[gender]:` 0 (male) or 1 (female);\n",
    "\t- `[race]:` integer from 0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern);\n",
    "\t- `[date&time]:` format of yyyymmddHHMMSSFFF, showing the date and time an image was collected to UTKFace.\n",
    "- As the dataset is very large, I provide some sample files in `img` folder.\n",
    "\n",
    "- The UTKFace Dataset can be downloaded [here](https://susanqq.github.io/UTKFace/).\n",
    "\n",
    "### CNN model\n",
    "- To perform the age estimation process, I choose as a deep learning model the classification segment state of art named DenseNet, according to ImageNet dataset report errors (21.46 in top-1 and 5.54 in top-5).\n",
    "- Below, a dense layer structure example:\n",
    "![dense layer](./img/DenseNet.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fFcY01wAWZ91"
   },
   "source": [
    "# Mount Drive in Google Colab and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "6_9I7RUUNZkv",
    "outputId": "16ff2354-ea98-4e15-a33c-cb8f94d65ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "GOOGLE_DRIVE_MOUNT_DIR = \"/content/drive\"\n",
    "drive.mount(GOOGLE_DRIVE_MOUNT_DIR, force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mogiz8ltWjkw",
    "outputId": "1418713d-eba0-4774-ac8f-2253f5c637ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking gpu available\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Spw2X52R91kf",
    "outputId": "04ada6b3-78e0-4fdf-a01c-ceb6e6a87e68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import datetime, os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.applications.densenet import DenseNet201, preprocess_input\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import losses, optimizers, activations\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivF1v69eCiAT"
   },
   "source": [
    "# Ages classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgxISU8wC5-O"
   },
   "outputs": [],
   "source": [
    "#dataset with 2 classes\n",
    "TRAIN_PATH = \"../content/drive/My Drive/Rede Neural/MY DATASETS/SPLIT Binary Ages Dataset/train\"\n",
    "VAL_PATH = \"../content/drive/My Drive/Rede Neural/MY DATASETS/SPLIT Binary Ages Dataset/val\"\n",
    "TEST_PATH = \"../content/drive/My Drive/Rede Neural/MY DATASETS/SPLIT Binary Ages Dataset/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "roITwXD3X6mG"
   },
   "outputs": [],
   "source": [
    "#dataset with 4 classes\n",
    "TRAIN_PATH = \"/content/drive/My Drive/Rede Neural/MY DATASETS/BALANCED UTK 4 Classes/train\"\n",
    "VAL_PATH = \"/content/drive/My Drive/Rede Neural/MY DATASETS/BALANCED UTK 4 Classes/val\"\n",
    "TEST_PATH = \"/content/drive/My Drive/Rede Neural/MY DATASETS/BALANCED UTK 4 Classes/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vC6_EuY6rU35"
   },
   "outputs": [],
   "source": [
    "#dataset with 7 classes\n",
    "TRAIN_PATH = \"/content/drive/My Drive/Rede Neural/MY DATASETS/FLIP Split Dataset Ages Balanced/train\"\n",
    "VAL_PATH = \"/content/drive/My Drive/Rede Neural/MY DATASETS/FLIP Split Dataset Ages Balanced/val\"\n",
    "TEST_PATH = \"/content/drive/My Drive/Rede Neural/MY DATASETS/test - balanced\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGZBuGRAOuDl"
   },
   "source": [
    "# Model Customization\n",
    "\n",
    "- The DenseNet201 base model was imported with ImageNet weights and the same UTK Face Dataset resolution (200x200).\n",
    "- I used some fine-tuning techniques to improve the classification performance:\n",
    "\t- **GlobalAveragePooling2d**: This layer applied after the base model helps the network to learn the correlation between all the filters during the training process. More specifically, a GlobalAveragePooling2d feed the filter average value through the next layers.\n",
    "\t- **Dropout**: As a regularization method, the Dropout layer keeps a percentage of neurons turned off during the training process (chosen randomly at each epoch). This process avoids co-dependencies between parameters that can lead neurons to overfitting. In this project, with 50% of neurons turned off, I obtained the best classification performance.\n",
    "- Loss and Activation Functions: \n",
    "    - **Categorical Cross-entropy**: A loss function calculates the gradients responsible for updating the neural network weights in the training process. The categorical cross-entropy is a loss function applied to multi-class classification tasks that calculates the probabilities of each class. Thereby, the categorization occurs based on the highest probability value.\n",
    "    - **Softmax**: Activation functions are mathematical equations responsible for the output value of a neural network. Softmax is an activation function highly recommended when the loss function is the categorical cross-entropy. This because the output values is a probabilities vector between 0 and 1. So, the softmax function can compare probabilities distributions resizing the model output to the right properties.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "A0piolF_qWNF",
    "outputId": "f0c8747b-736d-4180-ea08-40bff12832db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#change number of classes according your configuration\n",
    "CLASSES = 2\n",
    "\n",
    "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape = (200,200,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# training all the layers\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "filepath = \"/content/drive/My Drive/Rede Neural/Checkpoints/Age Classification/2classes.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "      \n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0MxMMWVCE4a"
   },
   "outputs": [],
   "source": [
    "#visualize trainable layers\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIDLMEbJL6Ue"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IbzAZoLqI8C_"
   },
   "source": [
    "# Data preparation\n",
    "- This code cell below gets all images for train, validation, and test from the Google Drive dataset directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "F-1mlihGKvmE",
    "outputId": "4f0b5482-d0c2-41f1-cbc0-b32b5e94552d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7196 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 254 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1-17': 0, '18-r': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WIDTH = 200\n",
    "HEIGHT = 200\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# data normalization\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#obtaining data from Google Drive directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "\t\tbatch_size=BATCH_SIZE,\n",
    "\t\tclass_mode='categorical',\n",
    "    shuffle=True)\n",
    "    \n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_generator.class_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0VtipKYj0t8J"
   },
   "source": [
    "# Initializing Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljNSQIKw3NXn"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1d6HUzs4dw7X"
   },
   "source": [
    "# Plot History of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dw_jbRmiN7Yu"
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5eX2MEi76z6"
   },
   "source": [
    "# Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GX_p-AfIxi6B"
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(test_generator, batch_size=BATCH_SIZE, verbose=1, steps=len(test_generator), workers=0)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['1-17', '18-116']\n",
    "print(classification_report(test_generator.classes, y_pred, digits=4, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QWRu-IeBtuxM"
   },
   "source": [
    "# Reload Model and Training process\n",
    "\n",
    "- If necessary, the model trained can be reloaded and retrained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tT1mpjtabokT"
   },
   "outputs": [],
   "source": [
    "model2 = load_model('/content/drive/My Drive/Rede Neural/Checkpoints/DenseNet-weights.best-class-newdivision-large.hdf5')\n",
    "\n",
    "for layer in model2.layers:\n",
    "  layer.trainable = True\n",
    "\n",
    "model2.compile(optimizer=optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUmHh1TXKf8R"
   },
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_tKDiZnmggqc"
   },
   "source": [
    "Reset generators and execute the Data Preparation process to create another random seed to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sXd9ZYaKJjlN"
   },
   "outputs": [],
   "source": [
    "train_generator.reset()\n",
    "validation_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Ik8XkZW0ige"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "filepath = \"/content/drive/My Drive/Rede Neural/Checkpoints/DenseNet-weights.best-class.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "\n",
    "history = model2.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=callbacks_list)\n",
    "  \n",
    "NAME = \"model-DenseNet-4-classes\"  \n",
    "model2.save(f\"/content/drive/My Drive/Rede Neural/Models/Ages Classes/{NAME}.model\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yBv7rEvdgLqk"
   },
   "source": [
    "# Making Predictions\n",
    "\n",
    "- In this code section, the best model trained can be loaded to generate the predictions in a CSV file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8n6Ce1KDmVzo"
   },
   "source": [
    "*For another prediction in the same process, reset test_generator to get a new random seed to images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0obyQ8FEmdfG"
   },
   "outputs": [],
   "source": [
    "test_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8oUAuWw7gSOA",
    "outputId": "b73d3308-a54c-4f86-dc7e-3f22f224a3ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 254 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1-17': 0, '18-r': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HEIGHT = 200\n",
    "WIDTH = 200\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CORRdDg1mgo4",
    "outputId": "0338b7d5-986c-409a-bc8d-e88a25727a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 277ms/step\n"
     ]
    }
   ],
   "source": [
    "model = load_model('/content/drive/My Drive/Rede Neural/Checkpoints/Age Classification/DenseNet-2classes.hdf5')\n",
    "\n",
    "pred = model.predict(test_generator, batch_size=32, verbose=1, steps=len(test_generator), workers=0)\n",
    "predicted_class_indices = np.argmax(pred, axis=1)\n",
    "labels = (test_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "results = pd.DataFrame({\"Filename\":filenames,\n",
    "                        \"Predictions\":predictions})\n",
    "\n",
    "#save CSV file\n",
    "results.to_csv(r'/content/drive/My Drive/Rede Neural/TESTS/2classes_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "V4UN2iBFkCTD",
    "outputId": "ada68544-8f09-41b4-dc40-9de99430310d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-17/10_0_0_20170110220654150.jpg.chip.jpg</td>\n",
       "      <td>1-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-17/10_1_0_20170109203501969.jpg.chip.jpg</td>\n",
       "      <td>1-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-17/10_1_2_20170109201545634.jpg.chip.jpg</td>\n",
       "      <td>1-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-17/10_1_3_20170109203848078.jpg.chip.jpg</td>\n",
       "      <td>1-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-17/10_1_4_20161223225900460.jpg.chip.jpg</td>\n",
       "      <td>1-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>18-r/84_1_2_20170120225608458.jpg.chip.jpg</td>\n",
       "      <td>18-r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>18-r/85_0_0_20170117192351268.jpg.chip.jpg</td>\n",
       "      <td>18-r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>18-r/86_1_0_20170110180113129.jpg.chip.jpg</td>\n",
       "      <td>18-r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>18-r/87_1_0_20170120225808097.jpg.chip.jpg</td>\n",
       "      <td>18-r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>18-r/90_0_0_20170111222149759.jpg.chip.jpg</td>\n",
       "      <td>18-r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Filename Predictions\n",
       "0    1-17/10_0_0_20170110220654150.jpg.chip.jpg        1-17\n",
       "1    1-17/10_1_0_20170109203501969.jpg.chip.jpg        1-17\n",
       "2    1-17/10_1_2_20170109201545634.jpg.chip.jpg        1-17\n",
       "3    1-17/10_1_3_20170109203848078.jpg.chip.jpg        1-17\n",
       "4    1-17/10_1_4_20161223225900460.jpg.chip.jpg        1-17\n",
       "..                                          ...         ...\n",
       "249  18-r/84_1_2_20170120225608458.jpg.chip.jpg        18-r\n",
       "250  18-r/85_0_0_20170117192351268.jpg.chip.jpg        18-r\n",
       "251  18-r/86_1_0_20170110180113129.jpg.chip.jpg        18-r\n",
       "252  18-r/87_1_0_20170120225808097.jpg.chip.jpg        18-r\n",
       "253  18-r/90_0_0_20170111222149759.jpg.chip.jpg        18-r\n",
       "\n",
       "[254 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing the filenames and respective predictions\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sW90B3f_O-cZ"
   },
   "source": [
    "# Reload best checkpoint and Confusion Matrix\n",
    "\n",
    "- This code cell below loads the best model saved with Checkpoint supervision and returns the Confusion Matrix and Classification Report with precision, recall, and f1-score values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6eOVv_XvEuX"
   },
   "outputs": [],
   "source": [
    "def show_results(model_path, test_generator, t_names):\n",
    "  model = load_model(model_path)\n",
    "\n",
    "  Y_pred = model.predict(test_generator, batch_size=32, verbose=1, steps=len(test_generator), workers=0)\n",
    "  y_pred = np.argmax(Y_pred, axis=1)\n",
    "  print('Confusion Matrix:')\n",
    "  print(confusion_matrix(test_generator.classes, y_pred))\n",
    "  print('\\nClassification Report:')\n",
    "  target_names = t_names\n",
    "  print(classification_report(test_generator.classes, y_pred, digits=4, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJfCZbazrj20"
   },
   "source": [
    "# Experiments\n",
    "\n",
    "- I saved the best models for each experiment and reloaded them to their respective cells below to show the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2FPJ5erqFTP"
   },
   "source": [
    "## Exp 1: classification in 7 age ranges: \n",
    "## ‘1–10’, ‘11–15’, ‘16–18’, ‘19–25’, ‘26–40’, ‘41–60’, ‘61–116’\n",
    "\n",
    "- Objective: There is a lot of machine learning projects that had explored CNN capacity to realize age recognition based on facial images, with some of them splitting the ages in groups. This experiment had the goal of split the ages in a similar number of groups from some reference authors for the entire project.\n",
    "- Distribution of split dataset:\n",
    "\n",
    "| Dataset | Number of images |\n",
    "| -- | -- |\n",
    "| Train | 4.998 |\n",
    "| Validation | 1.400 |\n",
    "| Test | 350 |\n",
    "| **Total** | **6.748** | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "fIgsAhEtwOBh",
    "outputId": "1201a57c-9c87-4192-f32a-6808e7125ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 108s 10s/step\n",
      "Confusion Matrix:\n",
      "[[41  5  2  0  2  0  0]\n",
      " [14 15 14  5  1  1  0]\n",
      " [ 2  5 23 15  3  1  1]\n",
      " [ 0  0  6 26 16  2  0]\n",
      " [ 0  0  0  3 41  5  1]\n",
      " [ 0  0  1  1 11 24 13]\n",
      " [ 0  0  0  0  0  3 47]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-10     0.7193    0.8200    0.7664        50\n",
      "       11-15     0.6000    0.3000    0.4000        50\n",
      "       16-18     0.5000    0.4600    0.4792        50\n",
      "       19-25     0.5200    0.5200    0.5200        50\n",
      "       26-40     0.5541    0.8200    0.6613        50\n",
      "       41-60     0.6667    0.4800    0.5581        50\n",
      "      61-116     0.7581    0.9400    0.8393        50\n",
      "\n",
      "    accuracy                         0.6200       350\n",
      "   macro avg     0.6169    0.6200    0.6035       350\n",
      "weighted avg     0.6169    0.6200    0.6035       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_results('/content/drive/My Drive/Rede Neural/Checkpoints/Age Classification/DenseNet-7classes.hdf5', \n",
    "             test_generator, \n",
    "             ['1-10', '11-15', '16-18', '19-25', '26-40', '41-60', '61-116'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEVaBST4p2pi"
   },
   "source": [
    "## Exp 2: classification in 4 age ranges: ‘1–13’, ‘14–17’, ‘18–35’, ‘36–116’\n",
    "\n",
    "- Objective: According to Brazilian law, possible crimes against minors under the age of 13 have more severe sentences. Thereby, this experiment had the objective of testing the CNN performance to differentiate two age groups of minors: 1-13 and 14-17. Besides these two groups, the 18-35 and 36-116 adult classes.  \n",
    "- Distribution of split dataset:\n",
    "\n",
    "| Dataset | Number of images |\n",
    "| -- | -- |\n",
    "| Train | 3.519 |\n",
    "| Validation | 800 |\n",
    "| Test | 400 |\n",
    "| **Total** | **4.719** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "2fopBjoAuROu",
    "outputId": "3fb96cee-0131-4d21-ea82-d114661c6f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 4s 300ms/step\n",
      "Confusion Matrix:\n",
      "[[84 12  4  0]\n",
      " [20 72  8  0]\n",
      " [ 8 23 57 12]\n",
      " [ 3  4 14 79]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-13     0.7304    0.8400    0.7814       100\n",
      "       14-17     0.6486    0.7200    0.6825       100\n",
      "       18-35     0.6867    0.5700    0.6230       100\n",
      "      36-116     0.8681    0.7900    0.8272       100\n",
      "\n",
      "    accuracy                         0.7300       400\n",
      "   macro avg     0.7335    0.7300    0.7285       400\n",
      "weighted avg     0.7335    0.7300    0.7285       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_results('/content/drive/My Drive/Rede Neural/Checkpoints/Age Classification/DenseNet-4classes.hdf5',\n",
    "             test_generator,\n",
    "             ['1-13', '14-17', '18-35', '36-116'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKiVqmTcqNZI"
   },
   "source": [
    "## Exp 3: classification in 2 age ranges: ‘1–17’, ‘18–116’\n",
    "\n",
    "- Objective: As the main objective of this project, to differentiate between minors and adults.\n",
    "- Distribution of split dataset:\n",
    "\n",
    "| Dataset | Number of images |\n",
    "| -- | -- |\n",
    "| Train | 7.196 |\n",
    "| Validation | 1.000 |\n",
    "| Test | 254 |\n",
    "| **Total** | **8.450** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "CDBgouOuuZtE",
    "outputId": "0154d2db-111b-42a9-e9d9-506070c18689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 309ms/step\n",
      "Confusion Matrix:\n",
      "[[122   5]\n",
      " [  3 124]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-17     0.9760    0.9606    0.9683       127\n",
      "      18-116     0.9612    0.9764    0.9688       127\n",
      "\n",
      "    accuracy                         0.9685       254\n",
      "   macro avg     0.9686    0.9685    0.9685       254\n",
      "weighted avg     0.9686    0.9685    0.9685       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_results('/content/drive/My Drive/Rede Neural/Checkpoints/Age Classification/DenseNet-2classes.hdf5',\n",
    "             test_generator,\n",
    "             ['1-17', '18-116'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wVD_bGZxvMTC"
   },
   "source": [
    "# Results\n",
    "- Were tested many configurations to find the best accuracy. The table below shows the most suitable ones.\n",
    "\n",
    "|Hyperparameter| Value |\n",
    "|--|--|\n",
    "| Loss Function | Categorical Crossentropy |\n",
    "| Dropout Keep Probability | 0.5 |\n",
    "| Batch Size | 32 |\n",
    "| Learning Rate | 0.001(Exp 1) 0.0001(Exp 2 and 3) |\n",
    "\n",
    "- For the proposed experiments, were used accuracy and f1-score as metrics, with the results below: \n",
    "\n",
    "|Experiment| Accuracy | f1-score\n",
    "|--|--|--|\n",
    "| 1 | 62.00% | 60.35% |\n",
    "| 2 | 73.00% | 72.85% |\n",
    "| 3 | 96.85% | 96.85% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9STU9i-r7Kq"
   },
   "source": [
    "# Conclusions\n",
    "- The main focus was to verify the deep learning capacity to differentiate between minors and adults. With almost 97% accuracy, the DenseNet architecture was highly performative.\n",
    "- In terms of applicability, this work showed that convolutional neural models can be seriously considered as an accurate mechanism for the identification of possible minors in digital images, considering different intervals of age group as a target for classification."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AgeRangeClassification-Densenet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
